
#How to Run the Script
#Save the Script: Copy the code into a Python file, e.g., text_summarizer.py.
#Install Required Libraries: Make sure you have the necessary libraries installed:pip install requests beautifulsoup4 gensim nltk
#Run the Script:
#python text_summarizer.py
#Input URL: When prompted, enter a valid URL of an article.


from nltk.tokenize import word_tokenize, sent_tokenize
from gensim.summarization import summarize
from bs4 import BeautifulSoup
import requests
import nltk
nltk.download("punkt")
nltk.download("stopwords")
def fetch_article(url):
    """Fetch the article content from the given URL."""
    try:
        response = requests.get(url)
        if response.status_code != 200:
            return f"Error: HTTP {response.status_code} - Unable to fetch the article."
        soup = BeautifulSoup(response.content, 'html.parser')
        paragraphs = soup.find_all('p')
        article_text = ' '.join([para.get_text() for para in paragraphs])
        return article_text

    except requests.exceptions.RequestException as e:
        return f"Request failed: {e}"

def preprocess_text(text):
    """Preprocess the text by tokenizing sentences and words."""
    sentences = sent_tokenize(text)
    words = word_tokenize(text)
    return sentences, words

def summarize_text(text):
    """Summarize the text using Gensim's summarize function."""
    try:
        return summarize(text)
    except ValueError:
        return "Text too short to summarize."

def extract_text_from_url(url):
    """Main function to fetch, preprocess, and summarize the article."""
    article_text = fetch_article(url)
    if "Error" in article_text or "failed" in article_text:
        return article_text

    sentences, words = preprocess_text(article_text)
    summary = summarize_text(article_text)

    return {
        'original_text': article_text,
        'sentences_count': len(sentences),
        'words_count': len(words),
        'summary': summary
    }
url = "https://en.wikipedia.org/wiki/Artificial_intelligence"  
result = extract_text_from_url(url)
print(result)
